{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Football_fullview-2 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1986982/1986982 [01:32<00:00, 21420.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Football_fullview-2 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38418/38418 [00:05<00:00, 7455.22it/s] \n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"uXBkznFQNgqHx4QCwl5V\")\n",
    "project = rf.workspace(\"football-sfolh\").project(\"football_fullview\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov11\")  \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Football-7/Football-7/valid'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.move('Football-7/train', 'Football-7/Football-7/train')\n",
    "# # shutil.move('Football-6/test', 'Football-6/Football-4/test')\n",
    "# shutil.move('Football-7/valid', 'Football-7/Football-7/valid')\n",
    "\n",
    "# # note this will take a while due to the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/lisms/jlia948/football-REID/training/Football_fullview-2'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting YOLOv11 training with model: /home/lisms/jlia948/football-REID/training/yolo11m.pt\n",
      "Ultralytics 8.3.95 ðŸš€ Python-3.8.10 torch-1.13.1+cu117 CUDA:0 (NVIDIA GeForce RTX 3090, 24259MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/home/lisms/jlia948/football-REID/training/yolo11m.pt, data=/home/lisms/jlia948/football-REID/training/Football_fullview-2/data.yaml, epochs=400, time=None, patience=50, batch=8, imgsz=1280, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train5\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    111872  ultralytics.nn.modules.block.C3k2            [128, 256, 1, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  1    444928  ultralytics.nn.modules.block.C3k2            [256, 512, 1, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    542720  ultralytics.nn.modules.block.C3k2            [1024, 256, 1, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1642496  ultralytics.nn.modules.block.C3k2            [1024, 512, 1, True]          \n",
      " 23        [16, 19, 22]  1   1413337  ultralytics.nn.modules.head.Detect           [3, [256, 512, 512]]          \n",
      "YOLO11m summary: 231 layers, 20,055,321 parameters, 20,055,305 gradients, 68.2 GFLOPs\n",
      "\n",
      "Transferred 643/649 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train5', view at http://localhost:6006/\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/lisms/jlia948/football-REID/training/Football_fullview-2/train/labels.cache... 18774 images, 25 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18774/18774 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/lisms/jlia948/football-REID/training/Football_fullview-2/valid/labels.cache... 304 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 304/304 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train5/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 106 weight(decay=0.0), 113 weight(decay=0.0005), 112 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train5\u001b[0m\n",
      "Starting training for 400 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2347 [00:00<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lisms/.local/bin/yolo\", line 8, in <module>\n",
      "    sys.exit(entrypoint())\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/cfg/__init__.py\", line 987, in entrypoint\n",
      "    getattr(model, mode)(**overrides)  # default args from model\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/engine/model.py\", line 791, in train\n",
      "    self.trainer.train()\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py\", line 211, in train\n",
      "    self._do_train(world_size)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/engine/trainer.py\", line 384, in _do_train\n",
      "    self.loss, self.loss_items = self.model(batch)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/tasks.py\", line 113, in forward\n",
      "    return self.loss(x, *args, **kwargs)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/tasks.py\", line 290, in loss\n",
      "    preds = self.forward(batch[\"img\"]) if preds is None else preds\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/tasks.py\", line 114, in forward\n",
      "    return self.predict(x, *args, **kwargs)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/tasks.py\", line 132, in predict\n",
      "    return self._predict_once(x, profile, visualize, embed)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/tasks.py\", line 153, in _predict_once\n",
      "    x = m(x)  # run\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/modules/block.py\", line 1478, in forward\n",
      "    a, b = self.cv1(x).split((self.c, self.c), dim=1)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/ultralytics/nn/modules/conv.py\", line 79, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/torch/nn/modules/activation.py\", line 395, in forward\n",
      "    return F.silu(input, inplace=self.inplace)\n",
      "  File \"/home/lisms/.local/lib/python3.8/site-packages/torch/nn/functional.py\", line 2058, in silu\n",
      "    return torch._C._nn.silu_(input)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 14.00 MiB (GPU 0; 23.69 GiB total capacity; 8.48 GiB already allocated; 83.69 MiB free; 8.52 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training failed with error code 1\n",
      "Error details: Command '['yolo', 'task=detect', 'mode=train', 'model=/home/lisms/jlia948/football-REID/training/yolo11m.pt', 'data=/home/lisms/jlia948/football-REID/training/Football_fullview-2/data.yaml', 'epochs=400', 'imgsz=1280', 'batch=8', 'augment=True', 'patience=50', 'verbose=True']' returned non-zero exit status 1.\n",
      "Total training time: 0h 0m 16.79s\n",
      "Or in seconds: 16.79s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_path = os.path.abspath(\"/home/lisms/jlia948/football-REID/training/yolo11m.pt\")\n",
    "\n",
    "try:\n",
    "    print(f\"Starting YOLOv11 training with model: {model_path}\")\n",
    "    subprocess.run([\n",
    "        \"yolo\",\n",
    "        \"task=detect\",\n",
    "        \"mode=train\",\n",
    "        f\"model={model_path}\",\n",
    "        f\"data={dataset.location}/data.yaml\",\n",
    "        \"epochs=400\",\n",
    "        \"imgsz=1280\",\n",
    "        \"batch=8\",\n",
    "        \"augment=True\",\n",
    "        \"patience=50\",\n",
    "        # Add verbose flag to get more information about what's happening\n",
    "        \"verbose=True\"\n",
    "    ], check=True)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Training failed with error code {e.returncode}\")\n",
    "    print(f\"Error details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "finally:\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    hours, remainder = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Total training time: {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "    print(f\"Or in seconds: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
